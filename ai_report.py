import feedparser
from datetime import datetime
import os
import requests

# 1. í•œêµ­ AI ë‰´ìŠ¤ RSS
RSS_URL = "https://news.google.com/rss/search?q=ì¸ê³µì§€ëŠ¥+OR+AI&hl=ko&gl=KR&ceid=KR:ko"
feed = feedparser.parse(RSS_URL)

now = datetime.now()
date_str = now.strftime("%Y-%m-%d")
time_str = now.strftime("%H:%M:%S")

OUTPUT_DIR = "reports"
os.makedirs(OUTPUT_DIR, exist_ok=True)
file_path = f"{OUTPUT_DIR}/ai_news_kr_{date_str}.md"

# 2. ìš”ì•½ í•¨ìˆ˜ (HuggingFace ë¬´ë£Œ)
def summarize(text):
    url = "https://api-inference.huggingface.co/models/facebook/bart-large-cnn"
    payload = {"inputs": text}

    try:
        r = requests.post(url, json=payload, timeout=10)

        # ìƒíƒœ ì½”ë“œ ì²´í¬
        if r.status_code != 200:
            return "ìš”ì•½ ìƒëµ (API ì œí•œ)"

        result = r.json()
        if isinstance(result, list) and "summary_text" in result[0]:
            return result[0]["summary_text"]

        return "ìš”ì•½ ìƒëµ (ì‘ë‹µ ì˜¤ë¥˜)"

    except Exception:
        return "ìš”ì•½ ìƒëµ (ì—°ê²° ì‹¤íŒ¨)"

# 3. ìƒìœ„ 5ê°œ ë‰´ìŠ¤ + ìš”ì•½
for i, entry in enumerate(feed.entries[:5], start=1):
    title = entry.title
    desc = entry.get("summary", "")
    text_for_summary = f"{title}. {desc}"

    summary = summarize(text_for_summary)

    lines.append(f"## {i}. {title}")
    lines.append(f"- ğŸ”— ë§í¬: {entry.link}")
    lines.append(f"- ğŸ§  ìš”ì•½: {summary}\n")

content = "\n".join(lines)

with open(file_path, "w", encoding="utf-8") as f:
    f.write(content)

print(f"Saved Korean AI news report to {file_path}")
